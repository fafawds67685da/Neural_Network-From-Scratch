{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as n\n",
        "import matplotlib.pyplot as m"
      ],
      "metadata": {
        "id": "raChYYnqXem3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1.2, 5.1, 2.1]\n",
        "weights = [3.1, 2.1, 8.7]\n",
        "bias = 3\n",
        "\n",
        "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jCT7YmaX5QX",
        "outputId": "34b88361-7ed7-4d72-f1b5-5b5c56f7c3eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.7"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2\n",
        "\n",
        "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7f1aiaHYQkv",
        "outputId": "1ac01d5d-62f9-4bfb-848f-50c5a428385e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [0.2, 0.8, -0.5, 1]\n",
        "bias = 2\n",
        "\n",
        "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] +inputs[3]*weights[3]+ bias\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNVz35eiZEiW",
        "outputId": "b7be290b-eda8-42e2-d686-1a281030148a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
        "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
        "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
        "bias1 = 2\n",
        "bias2 = 3\n",
        "bias3 = 0.5\n",
        "\n",
        "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] +inputs[3]*weights1[3]+ bias1,\n",
        "          inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] +inputs[3]*weights2[3]+ bias2,\n",
        "          inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] +inputs[3]*weights3[3]+ bias3]\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W64Axd6CQfRl",
        "outputId": "91b32a62-bfc9-4ac8-f349-05f1593088c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.8, 1.21, 2.385]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "\n",
        "layer_outputs = []\n",
        "for neuron_weights, neuron_biases in zip(weights, biases):\n",
        "  neuron_output = 0\n",
        "  for n_input, weight in zip(inputs, neuron_weights):\n",
        "    neuron_output += n_input*weight\n",
        "  neuron_output += neuron_biases\n",
        "  layer_outputs.append(neuron_output)\n",
        "\n",
        "layer_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkdE6hLAR_Oa",
        "outputId": "a30b1517-79e0-4bb8-a783-1411e5f396ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.8, 1.21, 2.385]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "\n",
        "weights=[0.2, 0.8, -0.5, 1.0]\n",
        "bias = 2\n",
        "\n",
        "output = n.dot(inputs, weights) + bias\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBbSKktCZdZy",
        "outputId": "a48e3f54-0457-41fd-bca0-01009ba9213f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "\n",
        "output = n.dot(weights, inputs) + biases\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktuKSbGPZ_O0",
        "outputId": "9902240f-6ddc-430b-a737-b314197648b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.8  , 1.21 , 2.385])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "\n",
        "output = n.dot(inputs, weights) + biases\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lPcSlQxXand7",
        "outputId": "3ca614fa-5e52-4ac3-d790-58962efa97f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (4,) and (3,4) not aligned: 4 (dim 0) != 3 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dcfbfe833638>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (4,) and (3,4) not aligned: 4 (dim 0) != 3 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [[1, 2, 3, 2.5],\n",
        "            [2.0, 5.0, -1.0, 2.0],\n",
        "            [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "\n",
        "output = n.dot(weights, inputs) + biases\n",
        "\n",
        "output"
      ],
      "metadata": {
        "id": "xqrRRzeJhK29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [[1, 2, 3, 2.5],          #transposing the matrix of weights to get the dot product\n",
        "            [2.0, 5.0, -1.0, 2.0],\n",
        "            [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "\n",
        "output = n.dot(inputs, n.array(weights).T) + biases\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9vKWTXXluBD",
        "outputId": "f33b8d85-f1d3-423e-a81d-153ba8e41a78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.8  ,  1.21 ,  2.385],\n",
              "       [ 8.9  , -1.81 ,  0.2  ],\n",
              "       [ 1.41 ,  1.051,  0.026]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [[1, 2, 3, 2.5],          #transposing the matrix of weights to get the dot product\n",
        "            [2.0, 5.0, -1.0, 2.0],\n",
        "            [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "weights=[[0.2, 0.8, -0.5, 1.0],\n",
        "         [0.5, -0.91, 0.26, -0.5],\n",
        "         [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "\n",
        "biases = [2,3,0.5]\n",
        "weights2 = [[0.1, -0.14, 0.5],\n",
        "            [-0.5, 0.12, -0.33],\n",
        "            [-0.44, 0.73, -0.13]]\n",
        "\n",
        "biases2 = [-1, 2, -0.5]\n",
        "\n",
        "layer1_output = n.dot(inputs, n.array(weights).T) + biases\n",
        "\n",
        "layer2_output = n.dot(layer1_output, n.array(weights2).T) + biases2\n",
        "\n",
        "layer2_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pquoE9uynvln",
        "outputId": "d89c83af-ba27-48db-947b-2549ce0bbfe9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5031 , -1.04185, -2.03875],\n",
              "       [ 0.2434 , -2.7332 , -5.7633 ],\n",
              "       [-0.99314,  1.41254, -0.35655]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X        = [[1, 2, 3, 2.5],         # Here X, is set of inputs having\n",
        "            [2.0, 5.0, -1.0, 2.0],  # 3 different sets (samples) of 4 input values.\n",
        "            [-1.5, 2.7, 3.3, -0.8]] #\n",
        "n.random.seed(0)\n",
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10* n.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = n.zeros((1, n_neurons))    #Shape: (1×5), meaning one bias per output neuron.\n",
        "  def forward(self, inputs ):\n",
        "    self.output = n.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "layer1 = Layer_Dense(4,50) #4 → Number of input neurons (matches the number of features in each sample).\n",
        "                          #5 → Number of output neurons (the layer transforms the input into 5 outputs per sample).\n",
        "                          #Shape: (4×5) → Because each of the 4 input neurons is connected to each of the 5 output neurons.\n",
        "layer2 = Layer_Dense(5,2)\n",
        "\n",
        "layer1.forward(X)\n",
        "print(\"Layer 1 \\n\",layer1.output) #(3×5) output means:\n",
        "                     #You got 5 output values per sample (from 5 output neurons).\n",
        "                     #Since you had 3 different input samples, you got 3 sets of 5 outputs.\n",
        "layer2.forward(layer1.output)\n",
        "print(\"Layer 2 \\n\",layer2.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GeSBBG01ybFA",
        "outputId": "0b345ead-9c52-487d-b7a3-c12f246f2fcd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 \n",
            " [[ 5.45196730e-01  1.41404182e-01 -5.71621434e-01  7.21722609e-02\n",
            "  -1.95430799e-01  4.05155370e-01  2.65885573e-01 -4.48860662e-01\n",
            "   1.52829141e-01  3.03211043e-01  3.15671843e-01  8.27713129e-01\n",
            "  -1.07537988e-01  2.61818277e-01 -3.06888339e-01  4.04838908e-01\n",
            "  -1.42510009e-01 -3.60655177e-01  3.31078356e-01  2.80877160e-01\n",
            "   2.33661496e-01 -1.58979882e-01  6.18002862e-01 -8.60222954e-02\n",
            "  -1.59487278e-01 -1.56890318e-01 -5.00982060e-01  2.47903356e-01\n",
            "   1.78772716e-01  2.84777286e-01 -5.37008526e-01  3.60184834e-02\n",
            "  -3.58850486e-01 -1.05163000e+00  2.28413263e-01  1.97228307e-01\n",
            "   2.55666392e-01  3.48046609e-02 -3.18971941e-01  2.38495267e-01\n",
            "  -9.56082191e-01  3.01067448e-01 -8.87906794e-02  2.88891403e-01\n",
            "   8.66070659e-01  3.37964467e-01 -2.04078562e-01  9.75904059e-01\n",
            "   1.00293980e-02  2.54780451e-01]\n",
            " [-2.96886202e-01  7.50927141e-01 -8.15574365e-02 -4.04364831e-01\n",
            "   4.57042319e-01 -3.08347417e-01  4.89965377e-01 -2.02763133e-02\n",
            "  -7.59592750e-01 -3.34866371e-01 -5.93783896e-01  4.06380066e-01\n",
            "   2.16411339e-02 -1.01230254e+00 -4.08010490e-02 -4.55286469e-02\n",
            "  -8.11051625e-01 -1.03093735e-01 -2.14837620e-01 -1.73678595e-01\n",
            "   4.76529563e-04  3.68900784e-01  8.84129887e-01 -1.02868962e+00\n",
            "   5.17729963e-01 -4.81995823e-01 -5.43413449e-01 -6.49697931e-01\n",
            "  -7.55639960e-03  2.84704073e-01 -5.45392610e-01  1.97130570e-01\n",
            "  -6.01634416e-03 -1.61214482e+00  8.63174565e-01  5.91159521e-01\n",
            "   5.56912172e-01  1.81776443e-01 -8.00354945e-01  8.84674383e-01\n",
            "  -5.20744689e-01  3.36689951e-01 -2.61640462e-01  5.81352754e-01\n",
            "  -5.74063831e-02  1.36914509e-01  3.31271138e-04  1.10143252e+00\n",
            "   3.04914408e-01  4.71910676e-01]\n",
            " [ 1.20515235e-01 -5.37387815e-01 -6.44407748e-01 -2.68888673e-01\n",
            "  -6.66997422e-01  9.56714541e-01 -3.51178750e-01 -5.58945735e-02\n",
            "   5.70584223e-01  3.64065595e-01  4.52966196e-01 -1.70588207e-01\n",
            "  -6.93863296e-01  1.38969780e-01 -9.08069741e-03  3.87295706e-02\n",
            "  -2.71655037e-01  2.28153306e-01 -1.84326905e-01  4.21112410e-01\n",
            "   6.30354644e-01 -4.51517877e-01  2.07844904e-01  2.67711175e-01\n",
            "  -3.78298917e-01 -7.06508331e-02 -3.21306907e-01  5.37209181e-01\n",
            "  -5.57361957e-02 -7.21750998e-02 -5.63585363e-01  4.74447110e-01\n",
            "   8.78564151e-02  7.07100113e-02  1.94167193e-01  8.39825332e-01\n",
            "   4.12352519e-01 -3.01848479e-01 -4.11569303e-02 -1.54104087e-01\n",
            "  -3.40261284e-01  6.66698051e-01  3.70319652e-01  2.74084085e-01\n",
            "   9.17242397e-01  5.81887838e-01 -1.72220269e-01  6.68296523e-01\n",
            "  -3.30957379e-01 -1.18796985e-01]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (3,50) and (5,2) not aligned: 50 (dim 1) != 5 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dc30eeed1de9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                      \u001b[0;31m#You got 5 output values per sample (from 5 output neurons).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                      \u001b[0;31m#Since you had 3 different input samples, you got 3 sets of 5 outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Layer 2 \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dc30eeed1de9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#Shape: (1×5), meaning one bias per output neuron.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer_Dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#4 → Number of input neurons (matches the number of features in each sample).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (3,50) and (5,2) not aligned: 50 (dim 1) != 5 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n.random.seed(0)\n",
        "\n",
        "X        = [[1, 2, 3, 2.5],\n",
        "            [2.0, 5.0, -1.0, 2.0],\n",
        "            [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
        "output = []\n",
        "\n",
        "for i in inputs: # Relu Activation function\n",
        "  if i > 0:\n",
        "    output.append(i)\n",
        "  else:\n",
        "    output.append(0)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2qXx5MmYpJ6",
        "outputId": "e7975bef-f102-46fb-ba2f-06fb05d0464e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsxVbNCeb4NB",
        "outputId": "186c6924-e0d6-4f8e-c2ea-4d5b0d360efc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nnfs) (1.26.4)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "X        = [[1, 2, 3, 2.5],\n",
        "            [2.0, 5.0, -1.0, 2.0],\n",
        "            [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "X, y = spiral_data(100, 3)\n",
        "\n",
        "class Layer_Dense:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10* n.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = n.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs ):\n",
        "    self.output = n.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "\n",
        "class Activation_ReLu:  #Activation function in the play\n",
        "  def forward(self, inputs):\n",
        "    self.output = n.maximum(0, inputs)\n",
        "\n",
        "layer1 = Layer_Dense(2,5)\n",
        "\n",
        "layer1.forward(X)\n",
        "activation1 = Activation_ReLu()\n",
        "activation1.forward(layer1.output)\n",
        "\n",
        "print(\"Layer 1 \\n\",activation1.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn0M_DcoZhRV",
        "outputId": "327bc1e9-1844-4ab5-d29d-61188163eaaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 \n",
            " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504505e-04\n",
            "  4.56846210e-05]\n",
            " [0.00000000e+00 5.93469958e-05 0.00000000e+00 2.03573116e-04\n",
            "  6.10024377e-04]\n",
            " ...\n",
            " [1.13291524e-01 0.00000000e+00 0.00000000e+00 8.11079666e-02\n",
            "  0.00000000e+00]\n",
            " [1.34588361e-01 0.00000000e+00 3.09493970e-02 5.66337556e-02\n",
            "  0.00000000e+00]\n",
            " [1.07817926e-01 0.00000000e+00 0.00000000e+00 8.72561932e-02\n",
            "  0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "E = math.e\n",
        "\n",
        "exp_values = []\n",
        "\n",
        "for output in layer_outputs:\n",
        "  exp_values.append(E**output) # exponential function\n",
        "\n",
        "print(exp_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKu8CF0HR6fN",
        "outputId": "e25dedbd-8daa-4d29-e617-0a0ac4acf3ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "E = math.e\n",
        "\n",
        "exp_values = []\n",
        "\n",
        "for output in layer_outputs:\n",
        "  exp_values.append(E**output) # exponential function\n",
        "\n",
        "print(exp_values)\n",
        "\n",
        "norm_base = sum(exp_values) # normalization of values for probability distribution\n",
        "norm_values = []\n",
        "\n",
        "for value in exp_values:\n",
        "  norm_values.append(value / norm_base)\n",
        "\n",
        "print(norm_values)\n",
        "print(sum(norm_values))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojdar956a9a1",
        "outputId": "526efb5e-6da7-410e-c2b4-b3b6205ac56d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n",
            "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [[4.8, 1.21, 2.385],\n",
        "                 [8.9, -1.81, 0.2],\n",
        "                 [1.41, 1.051, 0.026]]\n",
        "\n",
        "\n",
        "exp_values = n.exp(layer_outputs)\n",
        "\n",
        "print(n.sum(layer_outputs, axis=1))\n",
        "# norm_values = exp_values/n.sum(exp_values)\n",
        "\n",
        "# print(exp_values)\n",
        "# print(norm_values)\n",
        "# print(sum(norm_values))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_TFs1E3borq",
        "outputId": "4a980c94-ae94-4b6e-cb08-447a09b310a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.395 7.29  2.487]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [[4.8, 1.21, 2.385],\n",
        "                 [8.9, -1.81, 0.2],\n",
        "                 [1.41, 1.051, 0.026]]\n",
        "\n",
        "\n",
        "exp_values = n.exp(layer_outputs)\n",
        "\n",
        "print(n.sum(layer_outputs, axis=1, keepdims = True))\n",
        "# norm_values = exp_values/n.sum(exp_values)\n",
        "\n",
        "# print(exp_values)\n",
        "# print(norm_values)\n",
        "# print(sum(norm_values))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeSb_QFqfdmY",
        "outputId": "cbf35cb7-2e4b-41c2-f108-705684de1468"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.395]\n",
            " [7.29 ]\n",
            " [2.487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [[4.8, 1.21, 2.385],\n",
        "                 [8.9, -1.81, 0.2],\n",
        "                 [1.41, 1.051, 0.026]]\n",
        "\n",
        "\n",
        "exp_values = n.exp(layer_outputs)\n",
        "\n",
        "\n",
        "norm_values = exp_values/n.sum(exp_values, axis=1, keepdims = True)\n",
        "\n",
        "# print(exp_values)\n",
        "print(norm_values)\n",
        "print(sum(norm_values))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO_Yhd-zf0Iw",
        "outputId": "8abd401f-ce02-4b8c-9e0d-d712fb3c8fca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
            " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
            " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n",
            "[2.40819096 0.38306452 0.20874452]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "class Layer_Dense:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10* n.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = n.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs ):\n",
        "    self.output = n.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "\n",
        "class Activation_ReLu:  #Activation function in the play\n",
        "  def forward(self, inputs):\n",
        "    self.output = n.maximum(0, inputs)\n",
        "\n",
        "class Activation_softmax:\n",
        "  def forward(self, inputs):\n",
        "    exp_values = n.exp(inputs - n.max(inputs, axis=1, keepdims=True))\n",
        "    probabilities = exp_values / n.sum(exp_values, axis=1, keepdims=True)\n",
        "    self.output = probabilities\n",
        "\n",
        "X,y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "dense1 = Layer_Dense(2,3)\n",
        "activation1 = Activation_ReLu()\n",
        "\n",
        "dense2 = Layer_Dense(3,3)\n",
        "activation2 = Activation_softmax()\n",
        "\n",
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "print(activation2.output[:5])\n",
        "\n",
        "# 1. we first created fake weights of size 2,3\n",
        "# 2. then applied those weights on the dataset X\n",
        "# 3. then we applies relu activation function on it\n",
        "# 4. then we applies the fake weights 3x3 on the output of relu activation fuction\n",
        "# 5. then we applies softmax activation function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V99sPZIjhKV3",
        "outputId": "7240075b-b01d-45bb-f11c-e3f5e6596e62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.33331734 0.3333183  0.33336434]\n",
            " [0.3332888  0.33329153 0.33341965]\n",
            " [0.33325943 0.33326396 0.33347666]\n",
            " [0.33323312 0.33323926 0.33352762]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}